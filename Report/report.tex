%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\raggedright \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\usepackage{algorithm}
\usepackage{algpseudocode}
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text


\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Computer Architecture (Parallelism \& Locality) } \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Project 1.1 \\ % The assignment title
\huge Analytical Models of Locality within Matrix Multiply Algorithms
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Emily Bragg, Cagri Eryilmaz, Ali Fakhrzadehgan} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\newpage

%\section{Introduction}

\section{Single Level Analytical Models}
\subsection{Assumptions}
In this model there is only level of cache (L1) and there is no Register File in the architecture, so that the processor only operates on the data in memory, which obviously if it is present in L1 (Hit) it can be used directly and if it is not (Miss) it should be gathered first.\\
Cache organization is considered to be a \textit{fully associative}, ideal \textit{LRU} replacement policy, with cache-line/blocks size of \textit{L} and total cache size is \textit{Z}.\\
The analytical metric used here is the Arithmetic Intensity of the Matrix Multiplication. Basically, the multiplication algorithm is the well-known $O(N^{3})$ algorithm and in each step we are trying to optimize this procedure. Notice that, optimization can be done both on computation complexity and cache complexity of the algorithm, but here the main focus is to improve the cache complexity. 

\subsection{Multiplication Models}

\subsubsection{Baseline Matrix Multiplication Algorithm}
As it is provided in the attachments of this report, baseline core computation of matrix multiply looks like below.\\

\begin{algorithm}
\caption{Baseline Matrix Multiplication}
\label{Base-Alg}
\begin{algorithmic}
\For { $i = 0; i < N; i++ $ }
	\For { $j = 0; j < N; j++ $ }
		\State $C[ i ][ j ] = 0$;
		\For { $k = 0; k < N; k++ $ }
		\State $C[ i ][ j ] += A[ i ][ k ] \times B[ k ][ j ]$; 
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

By looking the Algorithm \ref{Base-Alg}, the asymptotic computation complexity could be figured out, which is $O(N^{3})$. However, since we need a more accurate metric here, we consider total number of arithmetic operations as $2N^{3}$  \footnote{ One $+$ and one $\times$.}. For this point on, since core of the computation is not changed, we consider number of operations to be the same.\\
Now we focus on the cache complexity of the computation. If we start from the third loop (the most inner one), we can see there are three data access. However, between these three, hopefully $C[ i ][ j ]$ is almost always present in the cache. This statement is true because before entering this loop, $C[ i ][ j ]$ is cached and it will resident for this whole loop according to the replacement policy\footnote{Since every assignment in this loop is addressing $C[ i ][ j ]$ repeatedly, so LRU will not remove it from the cache.}.\\
An important thing about the $A$ is, it is being traced in a row-major order, hence we can utilize the locality in each cache-line. Since each row of $A$ is $N$ words, it will require $\frac{N}{L}$ transfers of cache-lines.\\
Matrix $B$ is being trace in the column-major in this algorithm and since we are considering matrixes to be large in comparison with cache-line and cache size, there is almost no chance to observe any locality between consecutive access. Therefor, in each iteration $B$ will experience almost $N$ misses.\\
Putting it all together, $B$ will produce total number of $N^{3}$. However, $A$ will produce $\frac{N^{3}}{L}$ misses. Why? If we look closer to the access pattern of $B$ this accesses are re-writing the whole cache (with this assumption that $B$ is much larger than cache). Thus, although there is this opportunity of having \textit{Hits} from $A$ in the next iteration of middle loop, $B$'s access pattern removes these blocks. The important thing about $C$ is that it is being accessed in the second loop (the middle one) and begin traced in row-major order. Consequently, the total number of misses from $C$ would be $\frac{2N^{2}}{L}$. Using the arithmetic intensity of the operations, we will get:
\begin{equation*}
\text{Arithmetic Intensity} = \frac{2N^{3}}{ \frac{N^{3}}{L} + {N^{3}} + \frac{2N^{2}}{L} }
\end{equation*}

In other words, for accesses of $A$ in the most inner loop from each $L$ number of accesses, $L-1$ of them is services by the first level of cache ( $(L-1) * \frac{N}{L}$ ). So in total, $(L-1) * \frac{N^{3}}{L}$ of accesses are serviced via L1 and $\frac{N^{3}}{L}$ of them are missed (initiating a new transfer between memory and L1).\\
Obviously, since $B$'s access pattern is in column-major, it will not utilize its available locality so $0$.\\
Finally for $C$, from each $L$ iterations of the middle loop, $L-1$ of are serviced via L1. So, cache effect would be $(L-1) * \frac{N^{2}}{L}$.\\
This formulas make sense, since if we set $L = 1$ then number of useful accesses to L1 would be zero for all of them, which means we are completely loosing spatial locality. And making $L$ larger and larger, the limit would be total number of access, which is true and means we are utilizing the whole available spatial locality.

\subsubsection{Reordered Multiplication and Using Transposition}
In the last part the main reason for losing benefits of locality in consecutive accesses of $B$ was its access pattern. As mentioned above, this matrix is being access in column-major, so every access brings a new cache-block to the cache which will be used only once. This part is about improving this behavior.\\
As the first step, we can change the access pattern of B from column-major to row-major. By doing so, we can benefit from using all data words available in the cache-block brought into the cache in the previous iterations. This can simply done, by the following algorithm.\\

\begin{algorithm}
\caption{Matrix Multiplication with Reordering $B$ Accesses}
\label{Reorder-Alg}
\begin{algorithmic}
\For { $i = 0; i < N; i++ $ }
	\For { $k = 0; k < N; k++ $ }
		\For { $j = 0; j < N; j++ $ }
		\State $C[ i ][ j ] += A[ i ][ k ] \times B[ k ][ j ]$; 
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

What is being done in this algorithm is like this. Consider $A$, $B$, and $C$ as below.
\begin{equation*}
\begin{bmatrix}
C_{00} & ... & C_{0(N-1)} \\
 &...&\\
C_{(N-1)0} & ... & C_{(N-1)(N-1)}
\end{bmatrix} = 
\begin{bmatrix}
A_{00} & ... & A_{0(N-1)} \\
 &...&\\
A_{(N-1)0} & ... & A_{(N-1)(N-1)}
\end{bmatrix} \times
\begin{bmatrix}
B_{00} & ... & B_{0(N-1)} \\
 &...&\\
B_{(N-1)0} & ... & B_{(N-1)(N-1)}
\end{bmatrix}
\end{equation*}

Here, instead of producing each element of $C$, this algorithm tries to first produce partial multiplications of each element and then, in each step aggregates the values. For instance, one complete execution of the most inner loop (i.e. one iteration of middle loop), all of the first partial multiplications of first row of the $C$ is done.\\
This approach is good and bad. This is good, because accesses to $B$ become very similar to accesses to $A$. In other words, accessing $B$ in row-major results in less number of misses when accessing $B$, which is $\frac{N^{3}}{L}$. And it also may help removing $A$ block from the cache, because there are less number of blocking coming in/out to cache, so for $A$ we have $\frac{N^{2}}{L}$.\\
Although this reordering decreased number of $B$'s misses, but this can be harmful for $C$. Now, we have overhead on $C$. Why? Because computation of each element of $C$ is divided to many partial expressions which are being calculated/stored not necessarily on the same element/cache-block of $C$. In other words, when each of the $C$'s cache-lines are being fetched more than once\footnote{it is better to complete to whole operation on one cache-line instead of bringing back and forth.}. Thus, the inner loop on $C$ looks very similar to access patterns of $A$ and $B$, and produces total number of $\frac{2N^{3}}{L}$ misses (which means data movement). We can say:
\begin{equation*}
\text{Arithmetic Intensity} = \frac{2N^{3}}{ \frac{2N^{3}}{L} + \frac{N^{2}}{L} + \frac{N^{3}}{L} }
\end{equation*}

But still there is another idea, which instead of reordering the accesses to $B$, with some preprocess we can produce $B^{T}$. Using $B^{T}$ instead of $B$ and reordering the loops is another approach that can improve benefiting from the locality of $B$. Algorithm for this model using $B^{T}$ is like below.\\

\begin{algorithm}
\caption{Matrix Multiplication using $B^{T}$}
\label{Transpose-Alg}
\begin{algorithmic}
\For { $i = 0; i < N; i++ $ }
	\For { $j = 0; j < N; j++ $ }
		\State $C[ i ][ j ] = 0$;
		\For { $k = 0; k < N; k++ $ }
		\State $C[ i ][ j ] += A[ i ][ k ] \times B^{T}[ j ][ k ]$; 
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

Similarly, this algorithm has same access patterns for $A$ and $B$, however, it also benefits from the locality in $C$ access. So:
\begin{equation*}
\text{Arithmetic Intensity} = \frac{2N^{3}}{ \frac{2N^{2}}{L} + \frac{N^{2}}{L} + \frac{N^{3}}{L} }
\end{equation*}

\newpage
\subsubsection{Partitioning Matrixes and Divide\&Conquer (Cache aware and Cache Oblivious)  }
If consider the case which all of the matrixes are small enough which cache can hold them all (i.e. $3N^{2} < Z$), then number of data transfers (so amount of cache block which is transferred between memory and cache) will be reduced. In this case, the arithmetic Intensity would be:
\begin{equation*}
\text{Arithmetic Intensity} = \frac{2N^{3}}{\frac{4N^{2}}{L}} (Hmm?)
\end{equation*}

Thus, having small matrixes (in comparison with cache size) can improve locality or more accurately can improve utilizing the available locality. Smaller Matrixes can remain cache while they are being processes, so there is no extra overhead on transferring data (which reduces the denominator). The first idea to utilize this property is dividing each matrix to smaller sub-blocks which can be stored in cache completely (assuming that we know the size of the cache). Algorithm for this model of computation is similar to the base model with this difference that is being executed on $n \times n$ matrixes (Algorithm \ref{Block-Alg}).\\

\begin{algorithm}
\caption{Matrix Multiplication with $n \times n$ blocks}
\label{Block-Alg}
\begin{algorithmic}
\For { $I = 0; I < \frac{N}{n}; I++ $ }
	\For { $J = 0; J < \frac{N}{n}; J++ $ }
		\State $C_{IJ} = 0$;
		\For { $K = 0; K < \frac{N}{n}; K++ $ }
			\State $C_{IJ}$ += \text{MatMul( $A_{IK}$, $B_{KJ}$ )};
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

If we consider the size of the cache to be $Z$, $n \times n$ which can be completely stored in cache should have the property that $n < \sqrt{\frac{Z}{3}}$. Notice that, each of $C_{IJ}$, $A_{IK}$, and $B_{KJ}$ are chunks of original matrix and $+$ in the most inner loop is a Matrix Sum.\\
Assuming that $n < \sqrt{\frac{Z}{3}}$, for computing each sub-matrix we consume $ \frac{N}{n} \times (2\times n^{2})$ operations, which in total that would be $\frac{N}{n} \times (2\times n^{2}) \times (\frac{N}{n})^{2} = \frac{2N^{3}}{n}$. Using our assumption we have $\frac{2N^{3}}{\sqrt{\frac{Z}{3}}}$.\\
Number of data transfers (which directly depends on number of cache misses) in this model can be calculated as follow.  For each iteration of the middle loop we have:  1. Gathering $C_{IJ}$, which is $n^{2}$,  2. Gathering $A_{IK}$ and $B_{KJ}$ each of them for $\frac{N}{n}$ times. Hence, number of data transfers for the middle loop would be $2n^{2} + 2 \times \frac{N}{n} \times n^{2}$. This happens for $(\frac{N}{n})^{2}$, so $(\frac{N}{n})^{2} \times (2n^{2} + 2 \times \frac{N}{n} \times n^{2}) = 2N^{2} + \frac{2N^{3}}{n} = 2N^{2} + \frac{2N^{3}}{\sqrt{\frac{Z}{3}}}$.
\begin{equation*}
\text{Arithmetic Intensity} = \frac{\frac{N^{3}}{\sqrt{\frac{Z}{3}}}}{N^{2} + \frac{N^{3}}{\sqrt{\frac{Z}{3}}}}
\end{equation*}
As you can see, assumption here is based on the size of cache $Z$. However, we can go further and also eliminate this assumption (Cache Oblivious). We can do so, if we divide matrixes repeatedly to finer block. Obviously from some point on, we will pass the unknown cache size and every variable would be accessible from cache. This leads us to the Divide\&Conquer model which divides matrixes until it reaches some base case. Notice that, after passing the cache size further divisions does not have any impact.\\

\subsection{Graphs}
\section{Model with Two-Level Cache Hierarchy}
\subsection{Assumptions}
\subsection{Model}
\subsection{Graphs}
\section{Model with Two-Level Cache Hierarchy and Register File}
\subsection{Assumptions}
\subsection{Model}
\subsection{Graphs}

\begin{align} 
\begin{split}
(x+y)^3 	&= (x+y)^2(x+y)\\
&=(x^2+2xy+y^2)(x+y)\\
&=(x^3+2x^2y+xy^2) + (x^2y+2xy^2+y^3)\\
&=x^3+3x^2y+3xy^2+y^3
\end{split}					
\end{align}

Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies

%------------------------------------------------


Lorem ipsum dolor sit amet, consectetuer adipiscing elit. 
\begin{align}
A = 
\begin{bmatrix}
A_{11} & A_{21} \\
A_{21} & A_{22}
\end{bmatrix}
\end{align}
Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem.

%------------------------------------------------

\subsubsection{Heading on level 3 (subsubsection)}

\lipsum[3] % Dummy text

\paragraph{Heading on level 4 (paragraph)}

\lipsum[6] % Dummy text

%----------------------------------------------------------------------------------------
%	PROBLEM 2
%----------------------------------------------------------------------------------------

\section{Lists}

%------------------------------------------------

\subsection{Example of list (3*itemize)}
\begin{itemize}
	\item First item in a list 
		\begin{itemize}
		\item First item in a list 
			\begin{itemize}
			\item First item in a list 
			\item Second item in a list 
			\end{itemize}
		\item Second item in a list 
		\end{itemize}
	\item Second item in a list 
\end{itemize}

%------------------------------------------------

\subsection{Example of list (enumerate)}
\begin{enumerate}
\item First item in a list 
\item Second item in a list 
\item Third item in a list
\end{enumerate}

%----------------------------------------------------------------------------------------

\end{document}
